{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Did you encounter any challenges  ↑</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>How do you rate the platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Did you encounter any challenges  ↑  Unnamed: 1  \\\n",
       "0                                 NaN         NaN   \n",
       "1                          No comment         NaN   \n",
       "2                                 NaN         NaN   \n",
       "3                                 Yes         NaN   \n",
       "4                                 NaN         NaN   \n",
       "\n",
       "   How do you rate the platform  \n",
       "0                           7.0  \n",
       "1                           7.0  \n",
       "2                           7.0  \n",
       "3                           6.0  \n",
       "4                           3.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and clean data\n",
    "file_path = 'Data_Platform_Rating.xlsx'\n",
    "data = pd.read_excel(file_path, skiprows=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Did you encounter any challenges  ↑</th>\n",
       "      <th>How do you rate the platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No comment</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>261 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Did you encounter any challenges  ↑  How do you rate the platform\n",
       "0                                   NaN                           7.0\n",
       "1                            No comment                           7.0\n",
       "2                                   NaN                           7.0\n",
       "3                                   Yes                           6.0\n",
       "4                                   NaN                           3.0\n",
       "..                                  ...                           ...\n",
       "256                                 NaN                           7.0\n",
       "257                                 NaN                           7.0\n",
       "258                                 NaN                           7.0\n",
       "259                                 NaN                           7.0\n",
       "260                                 NaN                           6.0\n",
       "\n",
       "[261 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns='Unnamed: 1', inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Did you encounter any challenges  ↑', 'How do you rate the platform'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>challenges_encountered</th>\n",
       "      <th>platform_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No comment</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  challenges_encountered  platform_rating\n",
       "0                    NaN              7.0\n",
       "1             No comment              7.0\n",
       "2                    NaN              7.0\n",
       "3                    Yes              6.0\n",
       "4                    NaN              3.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.rename(columns={'Did you encounter any challenges  ↑':\n",
    "                           'challenges_encountered', \n",
    "                            'How do you rate the platform':\n",
    "                           'platform_rating'},\n",
    "                  )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and categorizing ratings\n",
    "def categorize_rating(rating):\n",
    "    if rating in [6, 7]:\n",
    "        return 'Highly Useful/Highly Unuseful'\n",
    "    elif rating in [4, 5]:\n",
    "        return 'Useful/Unuseful'\n",
    "    elif rating in [1, 2, 3]:\n",
    "        return 'Maybe Useful/Unuseful'\n",
    "    return 'Unknown'\n",
    "\n",
    "# Apply categorization\n",
    "data['Category'] = data['Platform Rating'].apply(categorize_rating)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences for each category\n",
    "category_counts = data['Category'].value_counts()\n",
    "\n",
    "# Generate Pie Chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "category_counts.plot(kind='pie', autopct='%1.1f%%', colors=['#4CAF50', '#FFC107', '#F44336'])\n",
    "plt.title('Feedback Distribution by Category')\n",
    "plt.ylabel('')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Bar Chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "category_counts.plot(kind='bar', color=['#4CAF50', '#FFC107', '#F44336'])\n",
    "plt.title('Number of Responses per Feedback Category')\n",
    "plt.xlabel('Feedback Category')\n",
    "plt.ylabel('Number of Responses')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "* If the data would be in a database, I would write the below SQL query which will return the output as above python code for data extraction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```-- Categorize feedback into the specified groups\n",
    "WITH CategorizedFeedback AS (\n",
    "    SELECT\n",
    "        CASE\n",
    "            WHEN Platform_Rating IN (6, 7) THEN 'Highly Useful/Highly Unuseful'\n",
    "            WHEN Platform_Rating IN (4, 5) THEN 'Useful/Unuseful'\n",
    "            WHEN Platform_Rating IN (1, 2, 3) THEN 'Maybe Useful/Unuseful'\n",
    "            ELSE 'Unknown'\n",
    "        END AS Feedback_Category,\n",
    "        COUNT(*) AS Feedback_Count\n",
    "    FROM Feedback\n",
    "    GROUP BY Feedback_Category\n",
    ")\n",
    "-- Display aggregated results\n",
    "SELECT * FROM CategorizedFeedback;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.B: \n",
    "If Moringa School wanted to gain deeper insights into student sentiment about the new platform, what changes would you recommend for the feedback form?\n",
    "\n",
    "Some of the recommendations would be to have a follow up question on the feedback form to those who responded with a yes to the question, 'Did you encounter any challenges?' If yes, the follow up question would be **What challenges did you encounter?**\n",
    "\n",
    "Then next question will be, 'In a scale of 1 to 5, 1 being easy and 5 being difficult, how easy was it for you to navigate the platform?'\n",
    "\n",
    "Another question to add would be 'What specific changes would improve your experience?'\n",
    "\n",
    "'In a scale of 1-5,How satisfied were you with the support you received?'\n",
    "\n",
    "With regards to the question of how do you rate the platform, it could be reframed to \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.C:\n",
    "How could Moringa School determine the likelihood of students recommending the platform to their peers using the existing feedback data? Additionally, what changes could be made to the feedback form to gather more actionable insights regarding student recommendations? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Determining Likelihood of Recommendations\n",
    "Using Existing Data:\n",
    "Correlation Analysis:\n",
    "\n",
    "Examine whether high ratings (6 or 7) correlate with positive comments or indicators of recommendation.\n",
    "Threshold Metric:\n",
    "\n",
    "Define a score threshold (e.g., an average of 6 or higher) as a proxy for likelihood to recommend.\n",
    "Recommended Changes:\n",
    "Net Promoter Score (NPS) Question:\n",
    "\n",
    "Add: \"On a scale of 1 to 10, how likely are you to recommend this platform to a peer?\"\n",
    "Categorize into Promoters (9-10), Passives (7-8), and Detractors (1-6).\n",
    "Peer Recommendation Query:\n",
    "\n",
    "Include: \"Have you already recommended the platform to anyone? (Yes/No).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the Likelihood of Students Recommending the Platform\n",
    "1. Using Existing Feedback Data\n",
    "While the current dataset does not explicitly include a \"likelihood to recommend\" metric, you can infer recommendations based on the provided ratings:\n",
    "\n",
    "Assumption: Higher ratings (6 or 7) correlate with a higher likelihood of recommending the platform, while lower ratings correlate with a lower likelihood.\n",
    "Steps to Analyze Recommendation Likelihood:\n",
    "Categorize Ratings:\n",
    "\n",
    "Group feedback into three categories:\n",
    "High Likelihood: Ratings of 6 or 7 (Highly Useful/Highly Unuseful).\n",
    "Moderate Likelihood: Ratings of 4 or 5 (Useful/Unuseful).\n",
    "Low Likelihood: Ratings of 1 to 3 (Maybe Useful/Unuseful).\n",
    "Calculate Proportions:\n",
    "\n",
    "Determine the percentage of responses in each category.\n",
    "Example: If 70% of responses fall under \"Highly Useful/Highly Unuseful,\" it can be inferred that 70% of respondents are likely to recommend the platform.\n",
    "Sentiment Correlation:\n",
    "\n",
    "Analyze the comments provided alongside the ratings (if available). Positive comments might strengthen the case for a high recommendation likelihood.\n",
    "Visualization:\n",
    "\n",
    "Create a bar or pie chart showing the proportion of each recommendation likelihood category for decision-makers.\n",
    "2. Proposed Changes to the Feedback Form\n",
    "To gather more actionable insights about recommendations, the feedback form should be enhanced as follows:\n",
    "\n",
    "A. Add a Direct Question About Recommendations\n",
    "Net Promoter Score (NPS):\n",
    "\n",
    "Question: \"On a scale of 0 to 10, how likely are you to recommend this platform to a peer?\"\n",
    "Categorization:\n",
    "Promoters: Scores of 9 or 10.\n",
    "Passives: Scores of 7 or 8.\n",
    "Detractors: Scores of 0 to 6.\n",
    "Rationale: NPS is a standard metric for measuring likelihood to recommend.\n",
    "Binary Question:\n",
    "\n",
    "Question: \"Have you already recommended this platform to someone? (Yes/No)\"\n",
    "Follow-up: \"If yes, what was the primary reason for recommending?\"\n",
    "B. Ask About Specific Features\n",
    "Usability: \"Which features of the platform do you find most helpful? (Multiple-choice or open-ended)\"\n",
    "Improvements: \"What specific improvements would make you more likely to recommend this platform?\"\n",
    "C. Emotional Sentiment\n",
    "\"How does using the platform make you feel? (Options: Motivated, Neutral, Frustrated, etc.)\"\n",
    "3. Implementation Benefits\n",
    "By analyzing NPS and binary recommendation responses, you’ll obtain a clearer picture of how students perceive the platform and their willingness to recommend it.\n",
    "Sentiment and feature-based questions provide actionable data for targeted improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize ratings\n",
    "def categorize_rating(rating):\n",
    "    if rating in [6, 7]:\n",
    "        return 'High Likelihood'\n",
    "    elif rating in [4, 5]:\n",
    "        return 'Moderate Likelihood'\n",
    "    elif rating in [1, 2, 3]:\n",
    "        return 'Low Likelihood'\n",
    "    return 'Unknown'\n",
    "\n",
    "data['likelihood_category'] = data['rating'].apply(categorize_rating)\n",
    "\n",
    "# Calculate percentages\n",
    "category_counts = df['likelihood_category'].value_counts(normalize=True) * 100\n",
    "print(\"Likelihood Category Percentages:\")\n",
    "print(category_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar chart for likelihood categories\n",
    "category_counts.plot(kind='bar', color=['#4CAF50', '#FFC107', '#F44336'])\n",
    "plt.title('Likelihood Categories')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()\n",
    "\n",
    "# Pie chart for sentiments\n",
    "sentiment_counts.plot(kind='pie', autopct='%1.1f%%', colors=['#4CAF50', '#FFC107', '#F44336'])\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.ylabel('')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1.D:\n",
    "\n",
    "D. Create a concise presentation summarizing your findings, recommendations, and proposed next steps based on the feedback analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(comment):\n",
    "    if pd.isnull(comment):\n",
    "        return 'Neutral'\n",
    "    comment = comment.lower()\n",
    "    if 'good' in comment or 'recommend' in comment or 'helpful' in comment:\n",
    "        return 'Positive'\n",
    "    elif 'bad' in comment or 'difficult' in comment or 'frustrating' in comment:\n",
    "        return 'Negative'\n",
    "    return 'Neutral'\n",
    "\n",
    "df['sentiment'] = df['comment'].apply(analyze_sentiment)\n",
    "\n",
    "# Count sentiments\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "print(\"\\nSentiment Counts:\")\n",
    "print(sentiment_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
